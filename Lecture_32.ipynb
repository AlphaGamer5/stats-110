{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 32\n",
    "# Markov chains (cont.), Google PageRank as a Markov chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Markov Chains\n",
    "\n",
    "Markov chains are memoryless, in a way, since the past doesn't really inform the future; only the present counts. Recall that the future is conditionally independent of the past, given the present.\n",
    "\n",
    "### Some key concepts\n",
    "\n",
    "* A chain is **irreducible** if it is possible to get from any state to another.\n",
    "* A state is **recurrent** if, when starting there, the chain has probability of 1.0 for returning to that state. Note that if there is probability 1.0 for returning to a certain state, then it follows that in a Markov chain, you can return to that state _infinitely_ many times with probability 1.0.\n",
    "* Otherwise, the state is **transient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "![title](images/L3201.png)\n",
    "\n",
    "* This Markov chain is _irreducible_, as it is indeed possible to go from any one state to another.\n",
    "* All of the states in this Markov chain are _recurrent_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "![title](images/L3202a.png)\n",
    "\n",
    "* In this example, the chain is _reducible_; notice how there are actually two chains (1-2-3 and 4-5-6).\n",
    "* However, note that all of the states are _recurrent_.\n",
    "\n",
    "And if we connected states 3 and 6...\n",
    "\n",
    "![title](images/L3202b.png)\n",
    "\n",
    "* This example is still not _irreducible_.\n",
    "* But states 1, 2 and 3 are now _transient_, since there is no way to return to any of those states once that edge from 3 to 6 is traversed.\n",
    "* The chain would become _irreducible_ and all states _recurrent_ if we added yet another edge from 4 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "![title](images/L3203.png)\n",
    "\n",
    "* The Markov chain in this example is _reducible_.\n",
    "* States 1 and 2 are _transient_.\n",
    "* States 0 and 3 are _recurrent_, but once you reach states 0 or 3, you cannot leave; these states are called _absorbing states_.\n",
    "* In case you didn't notice, the Markov chain in this example is the Gambler's Ruin, where a player either loses all her money (say state 0) or wins all the money (state 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4\n",
    "\n",
    "![title](images/L3204.png)\n",
    "\n",
    "* This is _periodic_ Markov chain.\n",
    "* It is _irreducible_.\n",
    "* All states are _recurrent_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
