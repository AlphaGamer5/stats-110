{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 34\n",
    "# A Look Ahead; Examples of Regression Example, Sampling from a Finite Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Top-10 List\n",
    "\n",
    "1. Conditioning ... is the soul of statistics!\n",
    "1. Symmetry ... is powerful but dangerous\n",
    "1. Random variables and their distributions\n",
    "1. Stories (proofs, backgrounds of the distributions covered)\n",
    "1. Linearity\n",
    "1. Indicator random variables\n",
    "1. LOTUS\n",
    "1. Law of Large Numbers\n",
    "1. Central Limit Theorem\n",
    "1. Markov Chains\n",
    "\n",
    "Items 1 through 4 deal with the Big Picture<sup>&trade;</sup> questions: _What is randomess? How do we think about uncertainty?_\n",
    "\n",
    "Items 5 through 7 are for computing expected values (mean, variance &amp; standard deviation).\n",
    "\n",
    "Items 8 through 10 are important for understanding long-run behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go from here?\n",
    "\n",
    "Some topics to study from here on out:\n",
    "\n",
    "* Statistical inference (we have data, need to estimate parameters or make predictions)\n",
    "* Regress &amp; linear models\n",
    "* Finance\n",
    "* Computational biology\n",
    "* Stochastic processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advice\n",
    "\n",
    "* Learn R\n",
    "* Learn C\n",
    "* Read Mostly Harmless Econometrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex. A Simple Linear Regression\n",
    "\n",
    "You've seen this before:\n",
    "\n",
    "\\begin{align}\n",
    "  Y &= \\beta_0 + \\beta_1 \\, X + \\epsilon\n",
    "\\end{align}\n",
    "\n",
    "* We want to use $X$ to predict $Y$\n",
    "* $\\beta_j$ are linear coeffiecients, with $\\beta_0$ being the value of $Y$ when $x=0$ (default value)\n",
    "* $\\epsilon$ error term (since $X$ is not perfect)\n",
    "* a common assumption is $\\mathbb{E}(\\epsilon | X) = 0$ (centered at 0, $\\epsilon$'s distribution may or may not be normal)\n",
    "\n",
    "So how would we solve for $\\beta_1$?\n",
    "\n",
    "We can start by treating $Cov$ as an _operator_!\n",
    "\n",
    "\\begin{align}\n",
    "  Cov(Y, X) &= Cov\\left( (\\beta_0 + \\beta_1 \\, X + \\epsilon), X \\right) \\\\\n",
    "  &= Cov(\\beta_0, X) + Cov\\left( (\\beta_1 \\, X), X\\right) + Cov(\\epsilon, X) \\\\\n",
    "  \\\\\n",
    "  \\text{now } Cov(\\beta_0, X) &= 0 &\\quad \\text{ since } Cov \\text{ of constant with anything is } 0 \\\\\n",
    "  \\\\\n",
    "  \\text{and } Cov\\left( (\\beta_1 \\, X), X\\right) &= \\beta_1 \\, Cov(X, X) &\\quad \\text{by definition of }Var \\\\\n",
    "  &= \\beta_1 \\, Var(X) \\\\\n",
    "  \\\\\n",
    "  \\text{and since } \\mathbb{E}(\\epsilon) &= \\mathbb{E}\\left( \\mathbb{E}(\\epsilon|X) \\right) = \\mathbb{E}(0) = 0 \\\\\n",
    "  \\text{and further } \\mathbb{E}(\\epsilon \\, X) &= \\mathbb{E}\\left( \\mathbb{E}(\\epsilon \\, X | X)  \\right) &\\quad \\text{ by Adam's Law} \\\\\n",
    "  &= \\mathbb{E}\\left( X \\mathbb{E}(\\epsilon | X) \\right) &\\quad \\text{ since } X \\text{ is known, we can pull it out} \\\\\n",
    "  &= \\mathbb{E}(0) \\\\\n",
    "  &= 0 \\\\\n",
    "  \\text{so }Cov(\\epsilon, X) &= \\mathbb{E}(\\epsilon \\, X) - \\mathbb{E}(\\epsilon) \\, \\mathbb{E}(X) \\\\\n",
    "  &= 0 - 0 = 0 \\\\\\\\\n",
    "  \\Rightarrow \\beta_1 &= \\frac{Cov(X,Y)}{Var(X)} &\\quad \\text{(population version)} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $\\beta_1$ with $Cov(X,Y)$ and $Var(X)$\n",
    "\n",
    "Here we calculate $\\beta_1 = \\frac{Cov(X,Y)}{Var(X)} \\,$ using [numpy.cov](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.cov.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64383561643835618"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([95, 85, 80, 70, 60])\n",
    "Y = np.array([85, 95, 70, 65, 70])\n",
    "\n",
    "# numpy.cov(X, Y) returns the matrix\n",
    "# [ Cov(X,X), Cov(X,Y)]\n",
    "# [ Cov(X,Y), Cov(Y,Y)]\n",
    "covM = np.cov(X,Y)\n",
    "\n",
    "beta_1 = covM[0,1]/covM[0,0]\n",
    "beta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $\\beta_1$ via sklearn LinearRegression API\n",
    "\n",
    "For comparison's sake, we also obtain $\\beta_1$ via [`sklearn.linear_model.LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64383561643835607"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(np.matrix(X).T, Y).coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ex. Sampling from a Finite Population\n",
    "\n",
    "Here's the set-up:\n",
    "\n",
    "* We have a finite population , size $N$.\n",
    "* Let $Y_1, Y_2, ..., Y_N$ be some value of interest (height, weight, opinion.\n",
    "* Each person in the population can be uniquely identified.\n",
    "* $Y_j$ are fixed, non-random values, but nevertheless _unknown_.\n",
    "* Using some sampling scheme to obtain a sample of size $n$.\n",
    "* Using this sample, we want to infer to the sum of $Y$ (or perhaps the average).\n",
    "* Assume that the _inclusion probability_ of person $j$ ending up in our sample is $p_j$ (assume that the true value is known). \n",
    "* Our sample data takes the form $(X_1, Z_1), (X_2, Z_2), ..., (X_n, Z_n)$, where\n",
    "   * $Z_j$ is the ID of the $j^{th}$ person in our sample\n",
    "   * $X_j = Y_j$\n",
    "\n",
    "### The difference between $X_j$ and $Y_j$\n",
    "\n",
    "It is important to understand the difference between $X_j$ and $Y_j$:\n",
    "\n",
    "* $Y_j$ is a **_fixed, non-random value_**.\n",
    "* $X_j$, due to our random sampling (person $j$ was randomly selected from the population with probability $p_j$), is a **_random variable_**.\n",
    "\n",
    "### How do we get an unbiased estimator for the total?\n",
    "\n",
    "Let $t_y$ be the true population total $\\sum_{1}^{N} Y_i$. How can we use random sampling of this finite population to find $\\hat{t}_y$? \n",
    "\n",
    "The claim is that $\\sum_{j=1}^{n} \\frac{X_j}{P_{Z_j}}$ is an unbiased estimator for $t_y$ we are looking for.\n",
    "\n",
    "\\begin{align}\n",
    "  t_y &= \\sum_{j=1}^{n} \\frac{X_j}{P_{Z_j}} \\\\\n",
    "  &= \\sum_{j=1}^{N} \\frac{I_j \\, Y_j}{P_j} &\\quad \\text{where } I_j = 1 \\text{ if person } j \\text{ included in sample}\\\\\\\\\n",
    "  \\mathbb{E}(t_y) &=  \\mathbb{E}\\left( \\sum_{j=1}^{N} \\frac{I_j \\, Y_j}{P_j} \\right) &\\quad \\text{ find expected value to get } \\hat{t_y} \\\\\n",
    "  &= \\sum_{j=1}^{N} \\frac{P_j \\, Y_j}{P_j} &\\quad \\text{ by linearity} \\\\\n",
    "  &= \\boxed{ \\sum_{j=1}^{N} Y_j }\n",
    "\\end{align}\n",
    "\n",
    "This is known as the Horvitz-Thompson Estimator, or alternately inverse probability weighting.\n",
    "\n",
    "_But is an unbiased estimator good?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
