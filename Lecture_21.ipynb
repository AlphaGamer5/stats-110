{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 20\n",
    "\n",
    "## Covariance, Correlation, Variance of a sum, Variance of Binomial & Hypergeometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Definition\n",
    "\n",
    "Covariance of any 2 random variables $X, Y$ is defined as\n",
    "\n",
    "\\begin{align}\n",
    "  Cov(X, Y) &= \\mathbb{E}\\left( (X - \\mathbb{E}(X)) (Y - \\mathbb{E}(Y)) \\right) \\\\\n",
    "  &= \\mathbb{E}(XY) - \\mathbb{E}(X) \\, \\mathbb{E}(Y) & \\quad \\text{similar to definition of variance}\n",
    "\\end{align}\n",
    "\n",
    "Covariance is a measure of how $X, Y$ might vary _in tandem_. \n",
    "\n",
    "If the product of $(X - \\mathbb{E}(X))$ and $(Y - \\mathbb{E}(Y))$ is _positive_ then that means that both values are either _positive_ ($X,Y$ tend to be greater than their respective means); or they are both _negative_ ($X,Y$ tend to be less than their means).\n",
    "\n",
    "Correlation is defined in terms of covariance, as you will see in a bit.\n",
    "\n",
    "### Properties\n",
    "\n",
    "\\begin{align}\n",
    "  & \\text{(1)} & Cov(X,X) &= Var(X) \\\\\n",
    "  \\\\\n",
    "  & \\text{(2)} & Cov(X,Y) &= Cov(Y,X) \\\\\n",
    "  \\\\\n",
    "  & \\text{(3)} & Cov(X, c) &= 0 & \\quad \\text{for some constant }c \\\\\n",
    "  \\\\\n",
    "  & \\text{(4)} & Cov(cX, Y) &= c \\, Cov(X,Y) & \\quad \\text{bilinearity} \\\\\n",
    "  \\\\\n",
    "  & \\text{(5)} & Cov(X, Y+Z) &= Cov(X,Y) + Cov(X,Z) & \\quad \\text{bilinearity} \\\\\n",
    "  \\\\\n",
    "  & \\text{(6)} & Cov(X+Y, Z+W) &= Cov(X,Z) + Cov(X,W) + Cov(Y,Z) + Cov(Y,W) & \\quad \\text{applying (5)} \\\\\n",
    "  \\\\\n",
    "  & \\Rightarrow & Cov \\left( \\sum_{i=1}^{m} a_{i} \\, X_{i},  \\sum_{j=1}^{n} b_{j} \\, Y_{j} \\right) &= \\sum_{i,j} a_{i} \\, b_{j} \\, Cov \\left( X_{i}, Y_{j} \\right) \\\\\n",
    "  \\\\\n",
    "  & \\text{(7)} & Var(X_1 + X_2) &=  Cov(X_1+X_2, X_1+X_2) \\\\\n",
    "  & & &= Cov(X_1, X_1) + Cov(X_1, X_2) + Cov(X_2, X_1) + Cov(X_2, X_2) \\\\\n",
    "  & & &= Var(X_1) + Var(X_2) + 2 \\, Cov(X_1, X_2) \\\\\n",
    "  \\\\\n",
    "  & \\Rightarrow & Var(X_1 + X_2) &= Var(X_1) + Var(X_2) & \\quad \\text{if }X_1, X_2 \\text{ are uncorrelated} \\\\\n",
    "  \\\\\n",
    "  & \\Rightarrow & Var(X_1 + \\dots + X_n) &= Var(X_1) + \\dots + Var(X_n) + 2 \\, \\sum_{i \\lt j} Cov(X_i, X_j) \\\\\n",
    "\\end{align} \n",
    "\n",
    "#### Bilinearity\n",
    "\n",
    "If you imagine treating one variable as fixed and then start working with the other, it sort of looks like _linearity_. It also sort of looks like the distributive property, too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Theorem If $X,Y$ are independent, then they are also uncorrelated, i.e., $Cov(X,Y) = 0$\n",
    "\n",
    "The converse is not true, however: $Cov(X,Y) = 0$ does not necessarily mean that $X,Y$ are independent.\n",
    "\n",
    "Consider $Z \\sim \\mathcal{N}(0,1)$, and $X \\sim Z, Y \\sim Z^2$.\n",
    "\n",
    "\\begin{align}\n",
    "  Cov(X,Y) &= \\mathbb{E}(XY) - \\mathbb{E}(X)\\,\\mathbb{E}(Y) \\\\\n",
    "  &= \\mathbb{E}(Z^3) - \\mathbb{E}(Z) \\, \\mathbb{E}(Z^2) \\\\\n",
    "  &= 0 - 0 & \\quad \\text{odd moments of }Z \\text{ are 0} \\\\\n",
    "  &= 0\n",
    "\\end{align}\n",
    "\n",
    "But given $X \\sim Z$, we know *exactly* everything about $Y$. And knowing $Y$, gives us everything about $X$, _except for the sign_.\n",
    "\n",
    "So $X,Y$ are dependent, yet their coveriance (and hence correlation) is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "Correlation is defined in terms of covariance.\n",
    "\n",
    "\\begin{align}\n",
    "  Corr(X,Y) &= \\frac{Cov(X,Y)}{SD(X)\\,SD(Y)} \\\\\n",
    "  &= Cov \\left( \\frac{X-\\mathbb{E}(X)}{SD(X)}, \\frac{Y-\\mathbb{E}(Y)}{SD(Y)} \\right) & \\quad \\text{standardize first, then find covariance} \\\\\n",
    "\\end{align}\n",
    "\n",
    "Correlation is dimensionless, and like standard deviation, is unit-less.\n",
    "\n",
    "Correlation also ranges from -1 to 1.\n",
    "\n",
    "### Theorem $-1 \\le Corr(X,Y) \\le 1$\n",
    "\n",
    "Without loss of generality, assume that $X,Y$ are already standarized (mean 0, variance 1).\n",
    "\n",
    "\\begin{align}\n",
    "  Var(X + Y) &= Var(X) + Var(Y) + 2\\, Corr(X,Y) \\\\\n",
    "  &= 1 + 1 + 2 \\, \\rho & \\quad \\text{ where } \\rho = Corr(X,Y) \\\\\n",
    "  &= 2 + 2 \\, \\rho \\\\\n",
    "  & \\Rightarrow \\rho \\text{ has a floor of }-1 & \\quad \\text{since Var is non-negative}\\\\\n",
    "  \\\\\n",
    "  Var(X - Y) &= Var(X) + Var(Y) - 2\\, Corr(X,Y) \\\\\n",
    "  & &= 2 - 2 \\, \\rho \\\\\n",
    "  & \\Rightarrow \\rho \\text{ has a ceiling of }1 \\\\\n",
    "  \\\\\n",
    "  &\\therefore -1 \\le Corr(X,Y) \\le 1 &\\quad \\blacksquare\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
