{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 14: Location, Scale and LOTUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standard Normal (from last time...)\n",
    "\n",
    "- $\\mathcal{Z} \\sim \\mathcal{N}(0,1)$\n",
    "- PDF $\\frac{1}{\\sqrt{2\\pi}} ~~ e^{-\\frac{z^2}{2}}$\n",
    "- CDF $\\Phi$\n",
    "- Mean $\\mathbb{E}(\\mathcal{Z}) = 0$\n",
    "- Variance $\\mathbb{Var}(\\mathcal{Z}) = \\mathbb{E}(\\mathcal{Z}^2) = 1$\n",
    "- Skew (3<sup>rd</sup> moment) $\\mathbb{E}(\\mathcal{Z^3}) = 0$ (odd moments are 0 since they are odd functions)\n",
    "- $-\\mathcal{Z} \\sim \\mathcal{N}(0,1)$ (by symmetry; this simply flips the bell curve about its mean)\n",
    "\n",
    "... and with the standard normal distribution under our belts, we can now turn to the more general form. \n",
    "\n",
    "But first let's revisit variance once more and extend what we know.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{Var}(X) &= \\mathbb{E}( (X - \\mathbb{E}X)^2 ) \\\\\n",
    "                  &= \\mathbb{E}X^2 - (\\mathbb{E}X)^2 & \\quad \\text{(1)} \\\\\n",
    "  \\\\\n",
    "  \\mathbb{Var}(X+c) &= \\mathbb{Var}(X) & \\quad \\text{(2)} \\\\\n",
    "  \\\\\n",
    "  \\mathbb{Var}(cX) &= c^2 ~~ \\mathbb{Var}(X) & \\quad \\text{(3)} \\\\\n",
    "  \\\\\n",
    "  \\mathbb{Var}(X+Y) &\\neq \\mathbb{Var}(X) + \\mathbb{Var}(Y) ~~ \\text{in general} & \\quad \\text{(4)} \n",
    "\\end{align}\n",
    "\n",
    "1. We know this.\n",
    "1. Adding a constant $c$ has no effect on $\\mathbb{Var}(X)$.\n",
    "1. $\\mathbb{Var}(X) \\ge 0$; $\\mathbb{Var}(X)=0$ if and only if $P(X=a) = 1$ for some $a$... _variance can never be negative!_\n",
    "1. Unlike expected value, variance is _not_ linear. But if $X$ and $Y$ are independent, then $\\mathbb{Var}(X+Y) = \\mathbb{Var}(X) + \\mathbb{Var}(Y)$.\n",
    "\n",
    "As a case in point for (4), consider\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{Var}(X + X) &= \\mathbb{Var}(2X) \\\\\n",
    "  &= 4 ~~ \\mathbb{Var}(X) & \\quad \\text{from (3) above} \\\\\n",
    "  &\\neq 2 ~~ \\mathbb{Var}(X) & \\quad \\blacksquare \\\\\n",
    "\\end{align}\n",
    "\n",
    "... and now we know enough about variance to return back to the general form of the normal distribution.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Normal Distribution\n",
    "\n",
    "### Description\n",
    "\n",
    "Let $X = \\mu + \\sigma \\mathcal{Z}$, where\n",
    "\n",
    "- $\\mu \\in \\mathbb{R}$ (also known as _location_)\n",
    "- $\\sigma \\gt 0$ (_standard deviation_, also known as _scale_)\n",
    "\n",
    "Then $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
    "\n",
    "### Expected value\n",
    "\n",
    "It follows immediately that\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(X) &= \\mu\n",
    "\\end{align}\n",
    "\n",
    "### Variance\n",
    "\n",
    "From what we know about variance,\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{Var}(\\mu + \\sigma \\mathcal{Z}) &= \\sigma^2 ~~ \\mathbb{Var}(\\mathcal{Z}) \\\\\n",
    "  &= \\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "Solving for $\\mathcal{Z}$, we have\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathcal{Z} &= \\frac{X - \\mu}{\\sigma}\n",
    "\\end{align}\n",
    "\n",
    "### CDF &amp; PDF\n",
    "\n",
    "For the general normal distribution, we can _standardize_ it to allow us to obtain both cdf and pdf.\n",
    "\n",
    "Given $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, we can get the cdf and pdf\n",
    "\n",
    "\\begin{align}\n",
    "  \\text{cdf} ~~ P(X \\le x) &= P\\left(\\frac{X-\\mu}{\\sigma} \\le \\frac{x - \\mu}{\\sigma}\\right) \\\\\n",
    "  &= \\Phi \\left(\\frac{x-\\mu}{\\sigma} \\right) \\\\\n",
    "  \\\\\n",
    "  \\Rightarrow \\text{pdf} ~~ \\Phi' \\left(\\frac{x-\\mu}{\\sigma} \\right) &= \\frac{1}{\\sigma} ~~ \\frac{1}{\\sqrt{2\\pi}} ~~ e^{-\\frac{\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}{2}}\n",
    "\\end{align}\n",
    "\n",
    "### $-X$\n",
    "\n",
    "We can also do $-X$, but apply what we've just covered.\n",
    "\n",
    "\\begin{align}\n",
    "  -X &= -\\mu + \\sigma (-\\mathcal{Z}) \\sim \\mathcal{N}(-\\mu, \\sigma^2)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "### Linearity?\n",
    "\n",
    "Later we will show that if $X_j \\sim \\mathcal{N}(\\mu, \\sigma^2)$ are independent (consider $j \\in {1,2}$), then $X_1 + X_2 \\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)$.\n",
    "\n",
    "\n",
    "### $\\Phi$ and the 68-95-98.7% Rule\n",
    "\n",
    "Since $\\Phi$ cannot be computed in terms of other functions, we have the 68-95-98.7% Rule.\n",
    "\n",
    "If $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then as a rule of thumb $\\Phi$ takes on the following values with relation to $\\sigma$:\n",
    "\n",
    "\\begin{align}\n",
    "  P(\\lvert X-\\mu \\rvert &\\le \\sigma) \\approx 0.68 \\\\\n",
    "  P(\\lvert X-\\mu \\rvert &\\le 2 \\sigma) \\approx 0.95 \\\\\n",
    "  P(\\lvert X-\\mu \\rvert &\\le 3 \\sigma) \\approx 0.987\n",
    "\\end{align}\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
