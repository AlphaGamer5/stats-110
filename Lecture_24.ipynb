{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 24\n",
    "# Gamma distribution, Poisson processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stirling's Approximation to the Factorial\n",
    "\n",
    "\\begin{align}\n",
    "  n! &= n \\, (n-1) \\, (n -1) \\, \\dots \\, 1 \\\\\n",
    "     &\\sim \\sqrt{2 \\pi n} \\, \\left( \\frac{n}{e} \\right)^{n}\n",
    "\\end{align}\n",
    "\n",
    "where $\\sim$ means that the ratio of the two number converges to 1 as $n$ approaches $\\infty$.\n",
    "\n",
    "This is fine when we are talking about $n \\in \\{1,2,3,\\dots\\}$, but have you ever wondered what $\\pi!$ is?\n",
    "\n",
    "For that, we need the Gamma function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma Function\n",
    "\n",
    "Just as an aside, the Beta and Gamma functions are closely related. The Gamma function should be amongst the Top 10 Functions of All Time (if there was ever such a list).\n",
    "\n",
    "\\begin{align}\n",
    "  \\Gamma(a) &= \\int_{0}^{\\infty} x^a \\, e^{-x} \\, \\frac{dx}{x} \\quad \\text{for any real }a \\gt 0 \\\\\n",
    "  &= \\int_{0}^{\\infty} x^{a-1} \\, e^{-x} \\, dx \\quad \\text{(alternately)}\n",
    "\\end{align}\n",
    "\n",
    "Note that if $a$ approaches 0 from the right, the $\\frac{dx}{x}$ is what drives that integral since $x^0 = 1$ and $e^{-0}=1$.\n",
    "\n",
    "But $\\int \\frac{dx}{x} = log(x)$ which blows up to $-\\infty$, which is why we restrict $a \\gt 0$.\n",
    "\n",
    "### Properties of the Gamma Function\n",
    "\n",
    "\\begin{align}\n",
    "  \\Gamma(n) &= (n-1)! \\quad \\text{where }n \\text{ is a positive integer} \\\\\n",
    "  \\\\\n",
    "  \\Gamma(x+1) &= x \\, \\Gamma(x) \\\\\n",
    "  \\\\\n",
    "  \\Gamma(\\frac{1}{2}) &= \\sqrt{\\pi}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma Distribution\n",
    "\n",
    "How would we derive a PDF that is based on the Gamma distribution? \n",
    "\n",
    "_By normalizing the Gamma function._\n",
    "\n",
    "\\begin{align}\n",
    "  1 &= \\int_{0}^{\\infty} c \\, x^a \\, e^{-x} \\, \\frac{dx}{x} \\\\\n",
    "  &= \\int_{0}^{\\infty} \\frac{1}{\\Gamma(a)} \\, x^a \\, e^{-x} \\, \\frac{dx}{x}\n",
    "\\end{align}\n",
    "\n",
    "And so the PDF for a Gamma distribution would be\n",
    "\n",
    "\\begin{align}\n",
    " Gamma(a,1) &= \\frac{1}{\\Gamma(a)} \\, x^a \\, e^{-x} \\, \\frac{dx}{x} \\quad \\text{for } x \\gt 0 \\\\\\\\\n",
    " \\\\\n",
    " \\text{More generally } Y &\\sim Gamma(a, \\lambda) \\\\\n",
    " \\text{Let } Y &= \\frac{X}{\\lambda} \\text{, where } X \\sim Gamma(a,1) \\\\\n",
    " \\rightarrow y &= \\frac{x}{\\lambda} \\\\\n",
    " x &= \\lambda \\, y \\\\\n",
    " \\frac{dx}{dy} &= \\lambda \\\\\n",
    " \\\\\n",
    " \\Rightarrow f_Y(y) &= f_X(x) \\, \\frac{dx}{dy} \\quad \\text{ transforming } X \\text{ to } Y \\\\\n",
    " &= \\frac{1}{\\Gamma(a)} \\, (\\lambda y)^a \\, e^{-\\lambda y} \\, \\frac{1}{\\lambda y} \\, \\lambda \\\\\n",
    " &= \\frac{1}{\\Gamma(a)} \\, (\\lambda y)^a \\, e^{-\\lambda y} \\, \\frac{1}{y} \\quad \\text{for } y \\gt 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Connecting the Gamma and Exponential, Poisson Distributions\n",
    "\n",
    "### Poisson Processes\n",
    "\n",
    "Recall Poisson processes, where the number of events happening in a certain time period $t$ is such that\n",
    "\n",
    "\\begin{align}\n",
    "  N_t &= \\text{number of events occuring up to time }t \\\\\n",
    "      &\\sim Pois(\\lambda, t)\n",
    "\\end{align}\n",
    "\n",
    "where the number of events occuring in disjoint time intervals are independent.\n",
    "\n",
    "Now earlier, we discussed how time $t$ is exponential. Consider $t_1$, the time until we observe the very first event.\n",
    "\n",
    "\\begin{align}\n",
    "  P(t_1 \\gt t) &= P(N_t = 0) &\\quad \\text{by definition} \\\\\n",
    "  &= \\frac{\\lambda^0 \\, e^{\\lambda t}}{0!} \\\\\n",
    "  &= e^{\\lambda t} \\\\\n",
    "  &= 1 - (1-e^{\\lambda t}) &\\quad \\text{1 - CDF of } Expo(\\lambda) \\\\\\\\\n",
    "  \\\\ \n",
    "  \\Rightarrow &\\text{time until first event } \\sim Expo(\\lambda)\n",
    "\\end{align}\n",
    "\n",
    "And so using this argument along with the memorylessness property, all of the other times between subsequent events $t_2, t_3, \\dots , t_n$ are also $Expo(\\lambda)$\n",
    "\n",
    "### Analogies: Geometric $\\rightarrow$ Negative binomial (discrete); Exponential $\\rightarrow$ Gamma (continuous)\n",
    "\n",
    "So the interarrival time for events in a Poisson process are i.i.d. $Expo(\\lambda)$.\n",
    "\n",
    "But what if we want to know $t_n$, the time of the $n^{th}$ arrival?\n",
    "\n",
    "\\begin{align}\n",
    "  T_n &= \\sum_{i=1}^{n} X_1, X_2, \\dots , X_n &\\quad \\text{where } X_i \\text{ is i.i.d. } Expo(\\lambda) \\\\\\\\\n",
    "  &\\sim Gamma(n, \\lambda) &\\quad \\text{ assuming } n \\text{ is an integer} \n",
    "\\end{align}\n",
    "\n",
    "Recall the relation between the geometric and negative binomial distributions:\n",
    "* In geometric $Geom(p)$, we count discrete time until $1^{st}$ success\n",
    "* In negative binomial $NB(n, p)$, we count discrete time until $n^{th}$ success ($\\sum_{i=1}^{n} X_i \\text{ where } X_i \\text{ i.i.d., } X_i \\sim Geom(\\lambda)$ )\n",
    "\n",
    "\n",
    "\n",
    "Well, there's is something analogous between the exponential and Gamma distributions:\n",
    "* In exponential $Expo(\\lambda)$, we count continuous time until $1^{st}$ success\n",
    "* In Gamma, we count continuous time until $n^{th}$ success ($\\sum_{i=1}^{n}  X_i \\text{ where } X_i \\text{ i.i.d, } X_i \\sim Expo(\\lambda)$ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments of Gamma\n",
    "\n",
    "Let $X \\sim Gamma(a,1)$\n",
    "\n",
    "Directly using LOTUS,\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathbb{E}(X^c) &= \\int_{0}^{\\infty} \\frac{1}{\\Gamma(a)} \\,x^c \\, x^a \\, e^{-x} \\, \\frac{dx}{x} \\\\\n",
    "  &= \\int_{0}^{\\infty} \\frac{1}{\\Gamma(a)} \\, x^{a+c} \\, e^{-x} \\, \\frac{dx}{x} \\\\\n",
    "  &= \\frac{\\Gamma(a+c)}{\\Gamma(a)} &\\quad \\text{, where } a+x \\gt 0 \\\\\\\\\n",
    "  \\\\\n",
    "  \\text{mean of } Gamma(n,1) &= \\mathbb{E}(X) \\\\\n",
    "  &= \\frac{\\Gamma(a+1)}{\\Gamma(a)} \\\\\n",
    "  &= \\frac{a \\, \\Gamma(a)}{\\Gamma(a)} \\\\\n",
    "  &= a \\\\\\\\\n",
    "  \\\\\n",
    "  2^{nd} \\text{ moment } Gamma(n,1) &= \\mathbb{E}(X^2) \\\\\n",
    "  &= \\frac{\\Gamma(a+2)}{\\Gamma(a)} \\\\\n",
    "  &= \\frac{(a+1) \\, \\Gamma(a+1)}{\\Gamma(a)} \\\\\n",
    "  &= \\frac{(a+1)a \\, \\Gamma(a)}{\\Gamma(a)} \\\\\n",
    "  &= a^2 + a \\\\\n",
    "  \\\\\n",
    "  \\Rightarrow \\text{Var of } Gamma(n,1) &=  \\mathbb{E}(X^2) - \\left( \\mathbb{E}(X)^2 \\right) \\\\\n",
    "  &= a^2 + a - a^2 \\\\\n",
    "  &= a \\\\\\\\\n",
    "  \\\\\n",
    "  \\text{mean of } Gamma(n,\\lambda) &= \\frac{a}{\\lambda} \\\\\n",
    "  \\text{Var of } Gamma(n,\\lambda) &= \\frac{a}{\\lambda^2} \\\\\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
